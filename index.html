<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>ðŸ¥‘ Jisu Han</title>

    <meta name="author" content="Jisu Han">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- <link rel="shortcut icon" href="images/avocado_1f951.png" type="image/png"> -->
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
    <style>
    a {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
        color: #3EAF92; /* ë¹¨ê°„ìƒ‰ */
  }
      body, p, h1, h2, h3, td, table, title, strong, em, span, .name {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
      }
    </style>
  </head>
  <body>
    <table style="width:120%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle;font-size: 1.2em;">
                <p class="name" style="text-align: center;">
                  Jisu Han
                </p>
<p>
Hi, I'm Jisu! I am a first-year Ph.D. student in the Interdisciplinary Program in Artificial Intelligence (IPAI) at 
<a href="https://www.snu.ac.kr/">Seoul National University</a>, and a member of the 
<a href="http://mindlab-snu.notion.site">M.IN.D Lab</a>, where I am fortunate to be advised by 
<a href="https://scholar.google.com/citations?user=lQlioBoAAAAJ&hl=en">Taesup Moon</a>.
</p>

<p>
  I obtained my Masterâ€™s Degree in the Graduate School of AI at 
  <a href="https://www.kaist.ac.kr/en/">KAIST</a>, in the 
  <a href="https://imsquared.github.io">Humanoid Generalization Lab</a> 
  directed by <a href="https://beomjoonkim.github.io">Beomjoon Kim</a>.
  I received my Bachelorâ€™s Degree in Computer Science from 
  <a href="http://ewha.ac.kr/">Ewha Womans University</a>.
</p>

                <p style="text-align:center">
                  <a href="mailto:jshcdi6658@gmail.com">Mail</a> &nbsp;/&nbsp;
                  <!-- <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/JisuHann">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/jisu-han-/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=ko&user=WWg5SyQAAAAJ">Google Scholar</a>&nbsp;/&nbsp;
                  <a href="https://x.com/jisu_han__">X</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:25%">
                <a href="images/jisu.png"><img style="width:90%;max-width:100%;object-fit: cover; border-radius: 5%;" alt="profile photo" src="images/jisu.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>My research interests lie in the intersection of robotics and machine learning. I am interested in developing foundation models for robotics that can generalize to new tasks and environments.</p>
                <p> (* denotes equal contribution) </p>
              </td>

            </tr>
          </tbody>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/ota.png" alt="clean-usnob" width="160" height="90">
              </td>
              <td width="75%" valign="middle">
                Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning
                <br>
                Hongjoon Ahn*, Heewoong Choi*, <strong>Jisu Han*</strong>, Taesup Moon
                <br>
                <i>Arxiv preprint 2025</i>
                <br>
                <a href="https://arxiv.org/abs/2505.12737">Arxiv</a>
              </td>
                <!-- <br>[<a href="data/CVPRW_2024_CR.pdf">Paper</a>][<a href="https://github.com/JisuHann/GoS">Github</a>]</p> -->
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/ham.png" alt="clean-usnob" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments
                <br>
                Yoonyoung Cho*, Junhyek Han*, <strong>Jisu Han</strong>, Beomjoon Kim
                <br>
                <i>Robotics: Science and Systems (RSS), 2025</i>
                <br>
                <a href="https://www.roboticsproceedings.org/rss21/p154.pdf">Paper</a> / <a href="https://unicorn-hamnet.github.io">Project</a>
              </td>
                <!-- <br>[<a href="data/CVPRW_2024_CR.pdf">Paper</a>][<a href="https://github.com/JisuHann/GoS">Github</a>]</p> -->
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/GoS.png" alt="clean-usnob" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                Adaptive visual abstraction via object token merging and pruning for efficient robot manipulation
                <br>
                <strong>Jisu Han</strong>
                <br>
                <i>CVPR Workshop (Causal and Object-Centric Representations for Robotics), 2024 <strong><span style="color: red;">Oral</span></strong></i>
                <br>
                <a href="data/CVPRW_2024_CR.pdf">Paper</a> / <a href="https://github.com/JisuHann/GoS">Github</a>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/POMDPs.png" alt="clean-usnob" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                Preference learning for guiding the tree search in continuous POMDPs
                <br>
                Jiyong Ahn, Sanghyeon Son, Dongryung Lee,  <strong>Jisu Han</strong>, Dongwon Son, and Beomjoon Kim.
                <br>
                <i>Conference on Robot Learnining (CoRL), 2023</i>
                <br>
                <a href="https://openreview.net/pdf?id=09UL1dCqf2n">Paper</a> / <a href="https://www.youtube.com/watch?v=sONwle96q-8">Video</a> / <a href="https://sites.google.com/view/preference-guided-pomcpow?usp=sharing">Project</a> / <a href="https://github.com/iMSquared/PGP">Github</a>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Projects (Coursework, Hackathons, etc.)</h2>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/wrasprobot.png" alt="clean-usnob" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              WraspRobot: Bug-catching Robot
              <br>
              <strong>Jisu Han</strong>, Jaehoon Choi, Gunwoo Choi, and Dongwook Lee
              <br>
                <i>Huggingface LeRobot WorldWide Hackerton, 2025 <strong><span style="color: red;">Top 10 Finalist</span></strong>  among 3,000+ global participants</i>
                <br>
              <a href="https://huggingface.co/spaces/LeRobot-worldwide-hackathon/winners">Huggingface Winner space</a> / <a href=https://x.com/clementdelangue/status/1935041692220146035?s=46">X</a>
            </td>
<!--             
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hybrid.png" alt="clean-usnob" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              Hybrid-Space Diffusion for Task and Motion Planning with Offline RL
              <br>
              <strong>Jisu Han</strong>, Yoonyoung Cho, and Haewon Jung
              <br>
              <i>AI707: Advanced Topics in Deep Learning (Prof. Kimin Lee) project</i>
              <br>
              <small>TL;DR To resolve the downward refinement issues from bi-level planning in Task and Motion planning (TAMP), we adopt
                hybrid-space diffusion model.</small>
              <br>
              <a href="https://general-bone-2b1.notion.site/AI707-Project-Hybrid-Space-Diffusion-for-Task-and-Motion-Planning-with-Offline-Data-ae60a49af358497b9abd775b26ce22b6">Project</a>
            </td>
            
          </tr> -->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/Untitled.png" alt="clean-usnob" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              Clarifying the task: Identifying task from human videos as a representation
              <br>
              <strong>Jisu Han</strong> and Doohyun Lee
              <br>
              <i>AI611: Machine Learning for Robotics (Prof. Joseph Lim) project, 2023</i>
              <br>
              <small> TL;DR To learn a generalized reward function that can be utilized on reinforcement learning, we devise a representation that can effectively disentangle environment information and task information.</small>
              <br>
              <a href="https://general-bone-2b1.notion.site/Clarifying-the-task-Identifying-task-from-human-videos-as-a-representation-for-Robotics-d9e9de56af7c4430bec137a0ff87027b">Project</a>
            </td>
            
          </tr>

<!-- 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/AI502.png" alt="clean-usnob" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              Auditory Resilience: Diffusion Techniques for Noise-Intensive Sound Datasets
              <br>
              Boryeong Cho,  <strong>Jisu Han</strong> and Jeongho Kim (AI502: Deep Learning (Prof. Jaesik Cho) Class project)
              <br>
              <p>TL;DR We conduct data augmentation via diffusion model in order to handle noisy data.</p>
              <p>[<a href="https://drive.google.com/file/d/1eJDuWY5OuJfx9cNVzKYKOcq_BJf7Teiz/view">Paper</a>]</p>
             </td>
            
          </tr> -->
<!-- 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/AI602.png" alt="clean-usnob" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              Compositional Meta Reinforcement Learning
              <br>
              Yoonyoung Cho and <strong>Jisu Han</strong>  
              <br>
              <i>AI614: Advanced deep learning (Prof. Sungju Hwang) project</i> 
              <br>
              <small>TL;DR We inject compositional reasoning for robots to quickly learn novel tasks by leveraging reusable elements from previous experiments.</small>
              <br>
              <a href="data/AI602_Project_Proposal.pdf">Paper</a>
             </td>
            
          </tr> -->


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MEME.png" alt="clean-usnob" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              Cart MEME: Deep Learning Based Autonomous-Driving Cart
              <br>
              <strong>Jisu Han</strong>, Jiyoon Park, Chaewon Kim, and Sangsoo Park
              <br>
              <i>Korea Information Processing Society (KIPS), 2021</i>
              <i></i> 
              <br>
              <a href="https://drive.google.com/file/d/1ag9G8vsFsSSmQ2D-LO98Xm0h-ufBH1wD/view?usp=sharing">Paper</a> / <a href=https://github.com/MEME-Phoenix"">Github</a>
             </td>
            
          </tr>

          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TheCodeEscape.png" alt="clean-usnob" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              TheCodeEscape: VR room escape game based on Unity3D and Oculus
              <br>
              <strong>Jisu Han</strong>, Minyeong Hwang, and Seoungwoon Jung
              <br>
              <i>KAIST MadCamp Final Project, 2019</i>
              <br>
              <a href="https://github.com/JisuHann/TheCodeEscape">Github</a> / <a href="https://youtu.be/2lT4zi3lCCA?si=S1uLuR5EjhtQBN0d">Demo</a>
            </td>
            
          </tr>


        </tbody></table>
        <p></p>
    </table>
  </body>
</html>
